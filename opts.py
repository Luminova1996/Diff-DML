import argparse

def build_opts():
    parser = argparse.ArgumentParser()
    parser.add_argument("--seed", type=int, default=100)
    parser.add_argument("--local_rank", type=int, default=-1)
    parser.add_argument("--port", type=str, default='3142')
    parser.add_argument("--dataset", type=str, default='cifar10')
    parser.add_argument("--dataset_part", type=int, default=-1,help="0:art, 1:sketch, 2:cartoon, 3:photo")
    parser.add_argument("--cutout", type=int, default=0, help="Randomly cut out a part of the image dataset during processing to test the uncertainty of the data after cutout.")
    parser.add_argument("--batch_size", type=int, default=100)
    parser.add_argument("--optimizer", type=str, default='SGD')
    parser.add_argument("--tokenizer_name", type=str, default='gpt2-large', help="used when processing text data")
    parser.add_argument("--epoch", type=int, default=350)
    parser.add_argument("--max_grad_norm", type=float, default=0.2)
    parser.add_argument("--smoothing_eps", type=float, default=0., help="eps for label smoothing")
    parser.add_argument("--dual_focal", type=float, default=0.)
    parser.add_argument("--focal", type=float, default=0.,help="gamma for focal loss")
    parser.add_argument("--huber_gamma", type=float, default=0., help="gamma for DTDP method")
    parser.add_argument("--huber_alpha", type=float, default=0., help="alpha for DTDP method")
    parser.add_argument("--DTDP", type=int, default=0, help="to use DTDP method, set it to 1")
    parser.add_argument("--MDCA_beta", type=float, default=0., help="beta for MDCA")
    parser.add_argument("--FDCA_beta", type=float, default=0., help="A method that has not achieved the desired effect")
    parser.add_argument("--FDCA_M", type=int, default=10, help="A method that has not achieved the desired effect")
    parser.add_argument("--MMCE_lambda", type=float, default=0., help="lambda for MMCE")
    parser.add_argument("--DCA_beta", type=float, default=0., help="beta for DCA")
    parser.add_argument("--scaling_method", type=str, default="None",help="None, temperature, vector, dirichlet")
    parser.add_argument("--fudge", type=int, default=0, help="A method that has not achieved the desired effect")
    parser.add_argument("--tb_record_every", type=int, default=50)
    parser.add_argument("--use_ce_max_epoch", type=int, default=-1, help="Use cross_entropy loss after a certain number of epochs during training. It can be set to -1 by default.")    
    parser.add_argument("--infos_load_from", type=str)
    parser.add_argument(
        "--fp16",
        action="store_true",
        default=False,
    )
    parser.add_argument("--save_checkpoint_every", type=int, default=100, help="deprecated")
    parser.add_argument("--checkpoint_path", type=str, default='log/')
    
    parser.add_argument("--self_align", type=int, default=0, help="deprecated")
    parser.add_argument("--self_align_delta", type=float, default=0., help="deprecated")
    parser.add_argument("--align_flag", type=int, default=1, help="Whether to use a method similar to DML (Deep Metric Learning) to conduct joint training of multiple models.")
    parser.add_argument("--align_weight", type=float, default=0.2, help="The weight of the KL divergence term in the loss of Model A.")
    parser.add_argument("--align_weight_B", type=float, default=1.0, help="The weight of the KL divergence term in the loss of Model B.")
    parser.add_argument("--threshold_loss_beta", type=float, default=0., help="deprecated")
    parser.add_argument("--p_threshold", type=float, default=1., help="deprecated")
    parser.add_argument("--norm_flag", type=int, default=0, help="deprecated")
    parser.add_argument("--ECE_bin", type=int, default=10)
    parser.add_argument("--baseline_acc", type=float, default=0.0, help="a for CSMAC")
    parser.add_argument("--acc_threshold", type=float, default=1.0, help="c for CSMAC")
    #### model_A
    parser.add_argument("--model_type_A", help="The type of Model A")
    parser.add_argument("--model_A_load_from", type=str)
    parser.add_argument("--init_model_A", type=str, default='gpt2-large', help="deprecated")
    parser.add_argument("--num_hidden_layers_A",type=int,default=0, help="Used in building MLP and CNN.")
    parser.add_argument("--lr_A", type=float, default=0.1, help="lr of model A")
    parser.add_argument("--fix_A",type=int,default=0, help="whether fix the params of A. if 1, A will not be trained")
    parser.add_argument("--hidden_size_A",type=int,default=256, help="Used in building MLP and CNN.")
    parser.add_argument("--kernel_size_A",type=int,default=3, help="Used in building MLP and CNN.")
    parser.add_argument("--hidden_channels_A",type=int,default=10, help="Used in building MLP and CNN.")
    parser.add_argument("--pretrained_A",type=int,default=0, help="set to 0")
    parser.add_argument("--train_A_after",type=int,default=-1, help="From which epoch to start training Model A. When it is set to -1, the training starts from the very beginning.")

    #### model_B
    parser.add_argument("--model_type_B", help="The type of Model B")
    parser.add_argument("--init_model_B", type=str, default='gpt2-large', help="deprecated")
    parser.add_argument("--num_hidden_layers_B",type=int,default=0, help="Used in building MLP and CNN.")
    parser.add_argument("--lr_B", type=float, default=0.01, help="lr of model A")
    parser.add_argument("--fix_B",type=int,default=0, help="whether fix the params of B. if 1, B will not be trained")
    parser.add_argument("--train_B",type=float,default=0., help="whether use cross-entropy loss in training B, when using DPLO, set it to 0")
    parser.add_argument("--hidden_size_B",type=int,default=256, help="Used in building MLP and CNN.")
    parser.add_argument("--kernel_size_B",type=int,default=3, help="Used in building MLP and CNN.")
    parser.add_argument("--hidden_channels_B",type=int,default=10, help="Used in building MLP and CNN.")
    parser.add_argument("--pretrained_B",type=int,default=0, help="set to 0")
    parser.add_argument("--lr_B_decay",type=int,default=0, help="whether decay the lr_B during training, when using DTS, set it to 0")
    parser.add_argument("--num_B",type=int,default=0, help="number of auxiliary models in DML")
    parser.add_argument("--lora_rank",type=int,default=8, help="ignore")
    parser.add_argument("--random_init",type=int,default=0, help="ignore")

    #### only for test
    parser.add_argument("--noise_level", type=int, default=0)

    #### ignore all the settings below
    parser.add_argument("--use_conf_model",type=int,default=0)
    parser.add_argument("--load_conf_model_from", type=str)
    parser.add_argument("--model_type_conf")
    parser.add_argument("--init_model_conf", type=str, default='gpt2-large')
    parser.add_argument("--num_hidden_layers_conf",type=int,default=0)
    parser.add_argument("--lr_conf", type=float, default=0.01)
    parser.add_argument("--fix_conf",type=int,default=0)
    parser.add_argument("--train_conf",type=float,default=0.)
    parser.add_argument("--hidden_size_conf",type=int,default=256)
    parser.add_argument("--kernel_size_conf",type=int,default=3)
    parser.add_argument("--hidden_channels_conf",type=int,default=10)
    parser.add_argument("--pretrained_conf",type=int,default=0)
    parser.add_argument("--lr_conf_decay",type=int,default=1)
    parser.add_argument("--use_conf_model_after",type=int,default=2)
    parser.add_argument("--stop_train_conf_after",type=int,default=150)
    parser.add_argument("--conf_pred_beta", type=float, default=0.)
    parser.add_argument("--conf_pred_mode", type=str, default='kl-div')
    parser.add_argument("--count_sample_acc", type=int, default=0)
    parser.add_argument("--count_sample_acc_len", type=int, default=-1)
    parser.add_argument("--count_acc_load_from", type=str, default=None)
    
    args = parser.parse_args()
    return args